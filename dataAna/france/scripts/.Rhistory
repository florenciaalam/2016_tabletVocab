print("# ** planned analysis **	Internal validity with cronbach alpha, using split trial")
# (we had also planned for a retest reliability but we didn't include those extra 13 trials)
# Santos, J. R. A. (1999). Cronbachs alpha: A tool for asedsing the reliability of scales. Journal of Extension, 37, 1–5.
print(alpha(cbind(data$pc_1,data$pc_2)))
print(alpha(cbind(data$rt_1,data$rt_2)))
# ** minor analyses **
print("# Test potential presence of side bias")
print(table(data$bias))  #19!!! out of 51 kids have a bias according to a crude measure that should be improved!!
print("# ** NUTSHELL **	Effect sizes")
dvs=c("trials_completed","trials_attempted","pc","rt_corr")
for(thisdv in dvs){
print(paste(thisdv,"d=",r2d(cor.test(data $trials_completed , data $edMom, method="spearman")$est),"\n","r=",cor.test(data $trials_completed , data $edMom, method="spearman")$est))
}
sink()
source("2B_genAllFigs.R")
resume(age)
summary(age)
summary(dtata$age)
table(age)
table(data$age)
mean(data$age)
View(data)
mean(data$age & lang=="monolingual")
mean(data$age & data$lang=="monolingual")
mean(data$age[data$lan=="monolingual"])
mean(data$age[data$lang=="monolingual"])
mean(data$lang=="monolingual"[data$age])
mean(data$age)
mean(data$age,data$lang=="monolingual")
mean(data$age,data$lang=="monolingual",data)
tapply(data$age,data$lang=="monolingual",mean)
tapply(data$age,data$lang=="bilingual" & data$lang=="multilingual",mean)
tapply(data$age,data$lang=="bilingual",mean)
tapply(data$age,data$lang=="multilingual",mean)
mean(2.63634,2764545)
(90x12)/100
(90*12)/100
63*12/100
77*12/100
30*12/100
# Analyse en R pour une étude sur la reconnaissance et l'apprentissage des mots 2015/2016
# mené sur Mandy -- SECTION ON VOCAB
# Base  Alex Cristia alecristia@gmail.com 2016-04-21
# Dernières modifs Charlotte Maniel 2016-07-12
### PRELIMINARIES: LOAD PACKAGES, DECLARE FUNCTIONS, SET PARAMETERS
minTrialN=9 #MINIMUM USABLE TRIALS TO BE INCLUDED IN OVERALL ANALYSES
minTrialNtype=4  #minimum amount of trials for each type   #notice that this means we will never look at crossing lexical type x difficulty level
extractVwithNA<-function(allkids,res_incl){
#add kids with no response data so that table can be square
#and then return the averaged parameter
names(res_incl)<-c("id","x")
if(sum(!(allkids %in% as.character(res_incl$id)))>0){
nakids=cbind(as.character(allkids [!(allkids %in% as.character(res_incl$id))]),NA)
colnames(nakids)<-c("id","x")
res_incl=rbind(res_incl,nakids)
}
res_incl = res_incl[order(res_incl $id),]
as.numeric(as.character(res_incl$x))
}
library(xlsx)
### END PRELIMINARIES
#*************************************************************************************************************************************
#### CSV DATA
## Read in the CSV
dirlist = dir(path="~/Dropbox/tabletAna/data")
data=NULL
for(thisdir in dirlist){
dir(paste("~/Dropbox/tabletAna/data",thisdir,sep="/"),pattern='csv')->allcsv
for(thisf in allcsv){
print(thisf)
read.csv(paste("~/Dropbox/tabletAna/data",thisdir,thisf,sep="/"))->thiscsv
data =rbind(data,cbind(thisdir,thisf,thiscsv))
}
}
dim(data)
write.table(data,"~/Dropbox/tabletAna/data.txt",row.names=F,sep="\t")
#*************************************************************************************************************************************
sumtab=NULL
for(thisuuid in levels(data$uuid)) sumtab=rbind(sumtab,cbind(thisuuid,sum(data$uuid==thisuuid),data[data$uuid==thisuuid,c("subject_id","config_profile","session_started_at","thisdir","thisf")][1,]))
write.table(sumtab,"~/Dropbox/tabletAna/_results/cm_sumtabCROSSac.txt",row.names=F,quote=F,sep="\t")
#several IDs have two sets of data!!
names(table(sumtab$subject_id))[table(sumtab$subject_id)>1]
#*************************************************************************************************************************************
read.table("~/Dropbox/tabletAna/data.txt",header=T)-> data
#remove non-relevant data
data=data[grep("C",data$level_name),   ]
#clean up subject id
data$subject_id=factor(data$uuid)
#*$* THROUGOUT SCRIPT, WE WILL COMPOSE A RESULTS TABLE, STARTING FROM NOTHING:
results=NULL
#*$* add ID info to the results table
results$id=sort(data$subject_id[data$trial_number_session==1])
#*$* add backgound info to the results table
results$school = data$thisdir[data$trial_number_session==1][order(data$subject_id[data$trial_number_session==1])]
results$date = data$date[data$trial_number_session==1][order(data$subject_id[data$trial_number_session==1])]
#*$*profile
results$profile = data$config_profile[data$trial_number_session==1][order(data$subject_id[data$trial_number_session==1])]
#### STEP 1: CLEAN UP
## Take into acount only test trials
data[-grep("Training", data $level_name),   ]-> data
#clean up names of objects
#data$object_asked=gsub("_.*","",data$object_asked)
dim(data) #4793 trials
#why am I not getting the same number???
#### STEP 2: RESULTS COLLAPSING ACROSS TRIAL TYPES
#*$*trials completed
results$trials_completed=as.numeric(table(data$subject_id))
#hist(data$object_touched_at)
#hist(data$object_touched_at[data $object_touched_at<9000])
## Exclusion criteria
#maximum time to answer
data[data $object_touched_at<7000,]-> data
#dim(data) #4537 trials
#*$* trials attempted
results$trials_attempted=as.numeric(table(data$subject_id))
#apply minimum amount of trials over the whole experiment
bbMinOK=names(table(data $subject_id)[table(data $subject_id)>minTrialN])
data[data $subject_id %in% bbMinOK,]-> data
#dim(data) #4529 trials
### ANALYSIS ACCURACY
#*$* percent correct (overall)
results$pc=extractVwithNA(levels(data$subject_id),	aggregate(data $correct,by=list(data $subject_id),mean))
###XXXXX###
#Calculate exclusion matrix
exclude = table(data$subject_id,data$correct) < minTrialNtype   #Apply minimum number of trials
### ANALYSIS RESPONSE TIMES
results$rt_corr=extractVwithNA(levels(data$subject_id),aggregate(data $object_touched_at[data$correct==1],by=list(data $subject_id[data$correct==1]),median))
results$rt_corr[exclude[,"1"]]<-NA
results$rt_incorr=extractVwithNA(levels(data$subject_id),aggregate(data $object_touched_at[data$correct==0],by=list(data $subject_id[data$correct==0]),median))
results$rt_incorr[exclude[,"0"]]<-NA
#*$* for reliability calculations, re-do proportion correct & RT corr from odd and even trials
data$spl=NA
for(each_child in levels(data$subject_id)) if(sum(data$subject_id==each_child) == length(rep(1:2,sum(data$subject_id==each_child)/2))) data$spl[data$subject_id==each_child]<-rep(1:2, sum(data$subject_id==each_child)/2) else data$spl[data$subject_id==each_child]<-c(rep(1:2, sum(data$subject_id==each_child)/2),1)
results$pc_1=extractVwithNA(levels(data$subject_id),aggregate(data $correct[data$spl==1],by=list(data $subject_id[data$spl==1]),mean))
results$pc_2=extractVwithNA(levels(data$subject_id),aggregate(data $correct[data$spl==2],by=list(data $subject_id[data$spl==2]),mean))
results$rt_1=extractVwithNA(levels(data$subject_id),aggregate(data $object_touched_at[data$spl==1],by=list(data $subject_id[data$spl==1]),median))
results$rt_2=extractVwithNA(levels(data$subject_id),aggregate(data $object_touched_at[data$spl==2],by=list(data $subject_id[data$spl==2]),median))
#*$* Write in the number of left responses
results$propLeft=as.numeric(as.character(table(data$subject_id,data$object_touched_position)[,1]))/results$trials_attempted
results$bias<-ifelse(results$propLeft <.4 | results$propLeft>.6,1,0)  #this should be improved!!
#### STEP 3: RESULTS SEPARATING DIFFERENT TRIAL TYPES
# Read in ancillary table
dif=read.xlsx("~/Dropbox/tabletAna/data/Difficultes.xlsx",1)
## Add useful info to the data sheet
#classify trials by word type & difficulty level
data$dif=NA
data$dif[as.character(data$object_asked) %in% as.character(dif$word[dif$level=="easy"])]<-"easy"
data$dif[as.character(data$object_asked) %in% as.character(dif$word[dif$level=="moderate"])]<-"moderate"
data$dif[as.character(data$object_asked) %in% as.character(dif$word[dif$level=="difficult"])]<-"difficult"
data$dif=factor(data$dif)
data$lex=NA
data$lex[as.character(data$object_asked) %in% as.character(dif$word[dif$wordtype =="adj"])]<-"adj"
data$lex[as.character(data$object_asked) %in% as.character(dif$word[dif$wordtype =="noun"])]<-"noun"
data$lex[as.character(data$object_asked) %in% as.character(dif$word[dif$wordtype =="verb"])]<-"verb"
#### by difficulty level
#Ns
results$N_easy=as.numeric(table(data$subject_id,data$dif)[,"easy"])
results$N_mod=as.numeric(table(data$subject_id,data$dif)[,"moderate"])
results$N_diff= as.numeric(table(data$subject_id,data$dif)[,"difficult"])
#Calculate exclusion matrix
exclude = table(data$subject_id,data$dif) < minTrialNtype   #Apply minimum number of trials
#*$* percent correct
results$pc_easy=extractVwithNA(levels(data$subject_id),aggregate(data $correct[data$dif=="easy"],by=list(data $subject_id[data$dif== "easy"]),mean))
results$pc_easy[exclude[,"easy"]]<-NA
results$pc_mod=extractVwithNA(levels(data$subject_id),aggregate(data $correct[data$dif=="moderate"],by=list(data $subject_id[data$dif== "moderate"]),mean))
results$pc_mod[exclude[,"moderate"]]<-NA
results$pc_diff=extractVwithNA(levels(data$subject_id),aggregate(data $correct[data$dif=="difficult"],by=list(data $subject_id[data$dif== "difficult"]),mean))
results$pc_diff[exclude[,"difficult"]]<-NA
#Calculate exclusion matrix
exclude = table(data$subject_id[data$correct==1],data$dif[data$correct==1]) < minTrialNtype   #Apply minimum number of trials
#*$* rt corr only
results$rt_easy=extractVwithNA(levels(data$subject_id),aggregate(data $object_touched_at[data$dif=="easy" & data$correct==1],by=list(data $subject_id[data$dif== "easy" & data$correct==1]), median))
results$rt_easy[exclude[,"easy"]]<-NA
results$rt_mod=extractVwithNA(levels(data$subject_id),aggregate(data $object_touched_at[data$dif=="moderate" & data$correct==1],by=list(data $subject_id[data$dif== "moderate" & data$correct==1]), median))
results$rt_mod[exclude[,"moderate"]]<-NA
results$rt_diff=extractVwithNA(levels(data$subject_id),aggregate(data $object_touched_at[data$dif=="difficult" & data$correct==1],by=list(data $subject_id[data$dif== "difficult" & data$correct==1]),median))
results$rt_diff[exclude[,"difficult"]]<-NA
#### by lexical type
#Ns
results$N_noun=as.numeric(table(data$subject_id,data$lex)[,"noun"])
results$N_adj=as.numeric(table(data$subject_id,data$lex)[,"adj"])
results$N_verb=as.numeric(table(data$subject_id,data$lex)[,"verb"])
#Calculate exclusion matrix
exclude = table(data$subject_id,data$lex) < minTrialNtype
#*$* percent correct
results$pc_noun=extractVwithNA(levels(data$subject_id),aggregate(data $correct[data$lex =="noun"],by=list(data $subject_id[data$lex== "noun"]),mean))
results$pc_noun[exclude[,"noun"]]<-NA
results$pc_adj =extractVwithNA(levels(data$subject_id),aggregate(data $correct[data$lex =="adj"],by=list(data $subject_id[data$lex== "adj"]),mean))
results$pc_adj[exclude[,"adj"]]<-NA
results$pc_verb =extractVwithNA(levels(data$subject_id),aggregate(data $correct[data$lex =="verb"],by=list(data $subject_id[data$lex== "verb"]),mean))
results$pc_verb[exclude[,"verb"]]<-NA
#*$* rt corr only
results$rt_noun=extractVwithNA(levels(data$subject_id),aggregate(data $object_touched_at[data$lex=="noun" & data$correct==1],by=list(data $subject_id[data$lex== "noun" & data$correct==1]), median))
results$rt_noun[exclude[,"noun"]]<-NA
results$rt_adj=extractVwithNA(levels(data$subject_id),aggregate(data $object_touched_at[data$lex=="adj" & data$correct==1],by=list(data $subject_id[data$lex== "adj" & data$correct==1]), median))
results$rt_adj[exclude[,"adj"]]<-NA
results$rt_verb=extractVwithNA(levels(data$subject_id),aggregate(data $object_touched_at[data$lex=="verb" & data$correct==1],by=list(data $subject_id[data$lex== "verb" & data$correct==1]),median))
results$rt_verb[exclude[,"verb"]]<-NA
#Squarify and write out
resultsdf=data.frame(results)
write.table(resultsdf,"~/Dropbox/tabletAna/_results/results.txt",row.names=F,quote=F,sep="\t")
#And also write out the final data
write.table(data,"~/Dropbox/tabletAna/_results/data_final.txt",row.names=F,quote=F,sep="\t")
## add individual information
read.table("~/Dropbox/tabletAna/_results/quest.txt",header=T)->quest
read.table("~/Dropbox/tabletAna/_results/corresp.txt",header=T)->corresp
merge(resultsdf,corresp,by.x="id",by.y="CSV")->resultsdf
merge(resultsdf,quest[c(1,2,3,4,5,17,18,19,20,23)],by.x="Anon",by.y="CA")->resultsdf
resultsdf$age=(as.Date(resultsdf$Date,"%d/%m/%Y") - as.Date(resultsdf$DOB,"%d/%m/%Y"))/365.25
resultsdf<-resultsdf[resultsdf$Remove=="no",]
resultsdf$ed=ifelse(resultsdf$edMom>7,"higher","lower")
write.table(resultsdf,"~/Dropbox/tabletAna/_results/cm_new_results.txt",row.names=F,sep="\t")
# Analyse en R pour une étude sur la reconnaissance et l'apprentissage des mots 2015/2016
# mené sur Mandy -- SECTION ON VOCAB
# Base  Alex Cristia alecristia@gmail.com 2016-04-21
# Dernières modifs Charlotte Maniel 2016-07-07
#IMPORTANT: uncomment the next line if important changes are made to table data, questionnaire, correspondance tables
#source("_scripts/_createDataSheets.R") #combines csv's together, stores tablet data, questionnaire, and correspondance table in _results
#IMPORTANT: uncomment the next line if important changes are made to the data pre-processing
#source("_scripts/_cm_2_new_preprocess.R") #calculates performance and RT per child, combines with other personal data
### PRELIMINARIES: LOAD PACKAGES, DECLARE FUNCTIONS, SET PARAMETERS
library(lme4)
library(car)
library(psych)
r2d<-function(r){(2*abs(r))/sqrt(1-abs(r)^2)}
### END PRELIMINARIES
# Read in & create tables to be used later
read.table("~/Dropbox/tabletAna/_results/cm_new_results.txt",header=T)->data
data$age.c=data$age-mean(data$age,na.rm=T)
data$langdummy = data$lang=="monolingual"
data$langdummy[is.na(data$langdummy)]<-F #LAIA, I think there is an issue with the bilingual category -- there should be an "other" (not mono, not bi)
data$lang2 = ifelse(data$lang=="monolingual","monolingual","other")
data$ed2=ifelse(data$edPar>7,"higher","lower")
rtstackcor=cbind(data[,c("id","ed","age.c","langdummy","school")], stack(data[,c("rt_corr","rt_incorr")]))
names(rtstackcor)[6:7]<-c("rt","resp")
pcstackdif=cbind(data[,c("id","ed","age.c","langdummy","school")], stack(data[,c("pc_easy","pc_mod","pc_diff")]))
names(pcstackdif)[6:7]<-c("pc","difficulty")
rtstackdif=cbind(data[,c("id","ed","age.c","langdummy","school")], stack(data[,c("rt_easy","rt_mod","rt_diff")]))
names(rtstackdif)[6:7]<-c("rt","difficulty")
pcstacklex=cbind(data[,c("id","ed","age.c","langdummy","school")], stack(data[,c("pc_noun","pc_adj","pc_verb")]))
names(pcstacklex)[6:7]<-c("pc","lexCat")
rtstacklex=cbind(data[,c("id","ed","age.c","langdummy","school")], stack(data[,c("rt_noun","rt_adj","rt_verb")]))
names(rtstacklex)[6:7]<-c("rt","lexCat")
#CHECKS
#boxplot(data$age~data$ed)
#need to add age to the models for sure
### 	ANALYed START
sink("~/Dropbox/tabletAna/_results/cm_new_stats_results.txt")
print(date())
print(dim(data))
print(summary(data))
print("# ** planned ANALYSIS 1 **	total number of trials completed")
#print(summary(lm(trials_completed ~ed+age.c,data=data))) #no difference across groups, marginal ages
print(summary(lm(trials_completed ~ed+age.c+langdummy,data=data))) #all NS
#plot(trials_completed ~age.c,data=data)
print("trials_completed, mean & SD")
print(cbind(c("Higher","Lower"),round(cbind(
aggregate(data $trials_completed ,by=list(data$ed),mean)$x,
aggregate(data $trials_completed ,by=list(data$ed),sd)$x),
3)))
print("trials_completed, range")
print(aggregate(data $trials_completed ,by=list(data$ed),range))
print("# ** planned ANALYSIS 2 **	total number of trials attempted")
#summary(lm(trials_attempted ~ed+age.c,data=data)) #no difference across groups, sign fx of age
summary(lm(trials_attempted ~ed+age.c+langdummy,data=data)) #no difference across groups, sign fx of age
print("trials_attempted, mean & SD")
print(cbind(c("Higher","Lower"),round(cbind(
aggregate(data $trials_attempted ,by=list(data$ed),mean)$x,
aggregate(data $trials_attempted ,by=list(data$ed),sd)$x),
3)))
print("trials_attempted, range")
print(aggregate(data $trials_attempted ,by=list(data$ed),range))
print("trials_attempted, distribution")
print(table(data $trials_attempted,data$ed))
print("# ** planned ANALYSIS 3 **	%correct & RT per group")
#print(summary(lm((pc - .5)~ed+age.c,data=data)))  #difference in percent correct by age but not ed
#print(summary(lm(log(rt_corr)~ed+age.c,data=data)))  #no difference in RT
##### ATTENTION!!! THIS SECTION IS IN PROGRESS!!!
mod1=glm(pc~ed+age.c+langdummy,data=data,family=binomial,weight= trials_attempted)
mod2=glm(pc~edMom+age.c+langdummy,data=data,family=binomial,weight= trials_attempted)
##### ATTENTION!!! END SECTION IN PROGRESS!!!
print(summary(lm((pc - .5)~ed+age.c+langdummy,data=data)))  #difference in percent correct by age and language, but not ed
print(summary(lm(log(rt_corr)~ed+age.c+langdummy,data=data)))  #no difference in RT
print(summary(lm((pc - .5)~ed+age.c+langdummy+school,data=data)))  #difference in percent correct by age and language, but not ed
print(summary(lm(log(rt_corr)~ed+age.c+langdummy+school,data=data)))  #no difference in RT
print("# ** ANALYSIS 3bis **	PC & RT per group (edPar)")
print(summary(lm((pc - .5)~ed2+age.c+langdummy,data=data))) #edPar as a categorical variable
print(summary(lm(log(rt_corr)~ed2+age.c+langdummy,data=data))) #edPar as a categorical variable
print("# ** not planned **	RT per group * corr")
mixedRTr=lmer(log(rt) ~ ed*resp+age.c + langdummy + (1|id),data= rtstackcor)  #marginal age & sig difficulty, but no ed & no interaction
print(Anova(mixedRTr))
summary(mixedRTr)
print("# ** ANALYSIS 4 **	%correct & RT per group * difficulty (check - not sure if we declared it)
")
#mixedPCdif=lmer((pc - .5)~ed*difficulty+age.c + (1|id),data= pcstackdif) # difficulty, NO age, no interaction
#print(Anova(mixedPCdif))
mixedPCdif=lmer((pc - .5)~ed*difficulty+age.c + langdummy + (1|id),data= pcstackdif) #age & difficulty & langdummy, no interaction
print(Anova(mixedPCdif))
print(summary(mixedPCdif))
mixedPCdif=lmer((pc - .5)~ed*difficulty+age.c + langdummy + school + (1|id),data= pcstackdif) #age & difficulty & langdummy, no interaction
print(Anova(mixedPCdif))
#mixedRTdif=lmer(log(rt) ~ ed*difficulty+age.c + (1|id),data= rtstackdif)  #marginal age & sig difficulty, but no ed & no interaction
#print(Anova(mixedRTdif))
mixedRTdif=lmer(log(rt) ~ ed*difficulty+age.c + langdummy + (1|id),data= rtstackdif)  #marginal age & sig difficulty, but no ed & no interaction
print(Anova(mixedRTdif))
print(summary(mixedRTdif))
mixedRTdif=lmer(log(rt) ~ ed*difficulty+age.c + langdummy + school + (1|id),data= rtstackdif)  #marginal age & sig difficulty, but no ed & no interaction
print(Anova(mixedRTdif))
print("# ** ANALYSIS 5 **	compare different conceptualizations of ed (maternal education, etc.)")
print("##TO DO")
print("# ** ANALYSIS 6 ** compare PC or RT as a fonction of sex")
print(summary(lm((pc - .5) ~ ed*sex + age,data=data)))
print(summary(lm(rt_corr ~ ed*sex + age,data=data)))
print("# ** analysis ** Differences by word type")
#mixedPClex=lmer((pc - .5)~ed* lexCat +age.c + (1|id),data= pcstacklex) #age & lex cat, BUT no ed nor ed*lex interaction
#print(Anova(mixedPClex))
mixedPClex=lmer((pc - .5)~ed* lexCat +age.c + langdummy + (1|id),data= pcstacklex) #age & lex cat & dummylang, BUT no ed nor ed*lex interaction
print(Anova(mixedPClex))
print(summary(mixedPClex))
mixedPClex=lmer((pc - .5)~ed* lexCat +age.c + langdummy + school + (1|id),data= pcstacklex) #age & lex cat & dummylang, BUT no ed nor ed*lex interaction
print(Anova(mixedPClex))
#mixedRTlex=lmer(log(rt) ~ ed* lexCat +age.c + (1|id),data= rtstacklex)  # lex cat, no ed or age and no interaction
#print(Anova(mixedRTlex))
mixedRTlex=lmer(log(rt) ~ ed* lexCat +age.c + langdummy+ (1|id),data= rtstacklex)  # lex cat & langdummy, no ed or age and no interaction
print(Anova(mixedRTlex))
print(summary(mixedRTlex))
mixedRTlex=lmer(log(rt) ~ ed* lexCat +age.c + langdummy + school + (1|id),data= rtstacklex)  # lex cat & langdummy, no ed or age and no interaction
print(Anova(mixedRTlex))
print("# ** planned analysis **	Internal validity with cronbach alpha, using split trial")
# (we had also planned for a retest reliability but we didn't include those extra 13 trials)
# Santos, J. R. A. (1999). Cronbachs alpha: A tool for asedsing the reliability of scales. Journal of Extension, 37, 1–5.
print(alpha(cbind(data$pc_1,data$pc_2)))
print(alpha(cbind(data$rt_1,data$rt_2)))
# ** minor analyses **
print("# Test potential presence of side bias")
print(table(data$bias))  #19!!! out of 51 kids have a bias according to a crude measure that should be improved!!
print("# ** NUTSHELL **	Effect sizes")
dvs=c("trials_completed","trials_attempted","pc","rt_corr")
for(thisdv in dvs){
print(paste(thisdv,"d=",r2d(cor.test(data $trials_completed , data $edMom, method="spearman")$est),"\n","r=",cor.test(data $trials_completed , data $edMom, method="spearman")$est))
}
######  PLOTS   ######
#boxplot and plot RT ~ SES (edMom or edPar)
boxplot(rt_corr ~ ed, data=data)
par(mar=c(4,4,1,1)+0.1,mgp=c(1.5,0.5,0))
mtext("SES (Ed mère)",1,line=2.5,cex=2)
mtext("RT corr (ms)",2,line=2.5,cex=2)
boxplot(rt_corr ~ ed2, data=data)
par(mar=c(4,4,1,1)+0.1,mgp=c(1.5,0.5,0))
mtext("SES (Ed par)",1,line=2.5,cex=2)
mtext("RT corr (ms) ",2,line=2.5,cex=2)
#plot PC and RT ~ edMom & creches
plot(pc ~ edMom,data=data,type="n")
par(mar=c(4,4,1,1)+0.1,mgp=c(1.5,0.5,0))
plot(pc ~ edMom,data=data,xlab="",ylab="",pch=20,cex.lab=2,cex=2,cex.axis=1)
mtext("Ed mère (années)",1,line=2.5,cex=2)
mtext("Réponses correctes (%)",2,line=2.5,cex=2)
points(pc ~ edMom,data=data,subset=c(school=="massena"),pch=20,col="red")
points(pc ~ edMom,data=data,subset=c(school=="fautrier"),pch=20,col="blue")
points(pc ~ edMom,data=data,subset=c(school=="dumeril"),pch=20,col="gray")
abline(h=0.5,lty=2,col="slategrey")
plot(rt_corr ~ edMom,data=data,type="n")
par(mar=c(4,4,1,1)+0.1,mgp=c(1.5,0.5,0))
plot(rt_corr ~ edMom,data=data,xlab="",ylab="",pch=20,cex.lab=1,cex=3,cex.axis=1)
mtext("Ed mère (années)",1,line=2.5,cex=2)
mtext("RT corr (ms)",2,line=2.5,cex=2)
points(rt_corr ~ edMom,data=data,subset=c(school=="massena"),pch=16,col="red")
points(rt_corr ~ edMom,data=data,subset=c(school=="fautrier"),pch=16,col="blue")
points(rt_corr ~ edMom,data=data,subset=c(school=="dumeril"),pch=16,col="gray")
#plot RT frequent words ~ RT less frequent & creches
plot(rt_diff ~ rt_easy,data=data,xlab="",ylab="",pch=20,cex.lab=1,cex=3,cex.axis=1,type="n")
par(mar=c(4,4,1,1)+0.1,mgp=c(1.5,0.5,0))
mtext("RT mots faciles (ms)",1,line=2.5,cex=2)
mtext("RT mots difficiles (ms)",2,line=2.5,cex=2)
points(rt_diff ~ rt_easy,data=data,subset=c(school=="massena"),pch=20,col="red")
points(rt_diff ~ rt_easy,data=data,subset=c(school=="fautrier"),pch=20,col="blue")
points(rt_diff ~ rt_easy,data=data,subset=c(school=="dumeril"),pch=20,col="gray")
lines(c(0,5000),c(0,5000),lty=2)
#plot RT frequent words ~ RT less frequent words & SES
plot(rt_diff ~ rt_easy,data=data,xlab="",ylab="",type="n",ylim=c(1000,4000),xlim=c(1000,4000))
par(mar=c(4,4,1,1)+0.1,mgp=c(1.5,0.5,0))
mtext("RT mots faciles (ms)",1,line=2.5,cex=2)
mtext("RT mots difficiles (ms)",2,line=2.5,cex=2)
points(rt_diff ~ rt_easy,data=data,subset=c(ed=="higher"),pch=20,col="deepskyblue3")
abline(lm(rt_diff ~  rt_easy,data=data, subset=c(ed=="higher" & !is.na(lang))),col="deepskyblue3")
points(rt_diff ~ rt_easy,data=data,subset=c(ed=="lower"),pch=22,col="sienna1")
abline(lm(rt_diff ~  rt_easy,data=data, subset=c(ed=="lower" & !is.na(lang))),col="sienna1")
lines(c(0,5000),c(0,5000),lty=2)
#plot RT frequent words ~ RT less frequent words & lang
plot(rt_diff ~ rt_easy,data=data,xlab="",ylab="",type="n",ylim=c(1000,4000),xlim=c(1000,4000))
par(mar=c(4,4,1,1)+0.1,mgp=c(1.5,0.5,0))
mtext("RT mots faciles (ms)",1,line=2.5,cex=2)
mtext("RT mots difficiles (ms)",2,line=2.5,cex=2)
points(rt_diff ~ rt_easy,data=data,subset=c(lang=="monolingual"),pch=25,col="red",bg="red")
abline(lm(rt_diff ~ rt_easy, data=data, subset=c(lang=="monolingual")), col="red")
points(rt_diff ~ rt_easy,data=data,subset=c(lang2=="other"),pch=20,col="black")
abline(lm(rt_diff ~ rt_easy, data=data, subset=c(lang2=="other")), col="black")
lines(c(0,5000),c(0,5000),lty=2)
#Plot PC and RT ~ age, difficulty level --> moche mais prend en compte le fait que chaque enfant a 3 points
plot(pc_easy ~ age, data=data,xlab="",ylab="",type="n",xlim=c(2,3.5), ylim=c(0,1))
mtext("Age (années)",1,line=2.5,cex=2)
mtext("Réponses correctes (%)",2,line=2.5,cex=2)
points(pc_easy ~ age,data=data,pch=20,col="forestgreen")
abline(lm(pc_easy ~ age, data=data),col="forestgreen")
points(pc_mod ~ age,data=data,pch=20,col="darkorange")
abline(lm(pc_mod ~ age,data=data),col="darkorange")
points(pc_diff ~ age,data=data,pch=20,col="firebrick2")
abline(lm(pc_diff ~ age,data=data),col="firebrick2")
abline(h=0.5,lty=2,col="slategrey")
plot(rt_easy ~ age, data=data,xlab="",ylab="",type="n")
mtext("Age (années)",1,line=2.5,cex=2)
mtext("RT corr (ms)",2,line=2.5,cex=2)
points(rt_easy ~ age ,data=data,pch=20,col="forestgreen")
abline(lm(rt_easy ~ age,data=data),col="forestgreen")
points(rt_mod ~ age,data=data,pch=20,col="darkorange")
abline(lm(rt_mod ~ age,data=data),col="darkorange")
points(rt_diff ~ age,data=data,pch=20,col="firebrick2")
abline(lm(rt_diff ~ age,data=data),col="firebrick2")
#Plot PC and RT ~ age.c & word type
plot(pc ~ age.c, data=data,xlab="",ylab="",type="n")
mtext("Age (années)",1,line=2.5,cex=2)
mtext("Réponses correctes (%)",2,line=2.5,cex=2)
points(pc ~ age.c,data=data,subset=c(dif$wordtype=="noun"),pch=20,col="red")
abline(lm(pc ~ age.c,subset=c(dif$wordtype=="noun"),data=data), col="red")
points(pc ~ age.c,data=data,subset=c(dif$wordtype=="adj"),pch=20,col="blue")
abline(lm(pc ~ age.c,subset=c(dif$wordtype=="adj"),data=data), col="blue")
points(pc ~ age.c,data=data,subset=c(dif$wordtype=="verb"),pch=20,col="black")
abline(lm(pc ~ age.c,subset=c(dif$wordtype=="verb"),data=data), col="black")
abline(h=0.5,lty=2,col="slategrey")
plot(rt_corr ~ age.c, data=data,xlab="",ylab="",type="n")
mtext("Age (années)",1,line=2.5,cex=2)
mtext("RT corr (ms)",2,line=2.5,cex=2)
points(rt_corr ~ age.c,data=data,subset=c(dif$wordtype=="noun"),pch=20,col="red")
abline(lm(rt_corr ~ age.c,data=data,subset=c(dif$wordtype=="noun")),col="red")
points(rt_corr ~ age.c,data=data,subset=c(dif$wordtype=="adj"),pch=20,col="blue")
abline(lm(rt_corr ~ age.c,data=data,subset=c(dif$wordtype=="adj")),col="blue")
points(rt_corr ~ age.c,data=data,subset=c(dif$wordtype=="verb"),pch=20,col="black")
abline(lm(rt_corr ~ age.c,data=data,subset=c(dif$wordtype=="verb")),col="black")
#Plot PC and RT ~ edMom & lang
par(mar=c(4,4,1,1)+0.1,mgp=c(1.5,0.5,0))
plot(pc ~ edMom,data=data,xlab="",ylab="",pch=20,cex.lab=2,cex=3,cex.axis=1,type="n")
mtext("Ed mère (années)",1,line=2.5,cex=2)
mtext("Réponses correctes (%)",2,line=2.5,cex=2)
points(pc ~ edMom,data=data,subset=c(lang=="monolingual" & !is.na(lang)),pch=25,bg="red",col="red")
abline(lm(pc ~  edMom,subset=c(lang2=="monolingual" & !is.na(lang)),data=data),col="red")
points(pc ~ edMom,data=data,subset=c(lang2=="other" & !is.na(lang)),pch=20,col="black")
abline(lm(pc ~  edMom,subset=c(lang2=="other" & !is.na(lang)),data=data),col="black")
abline(h=0.5,lty=2,col="slategrey")
par(mar=c(4,4,1,1)+0.1,mgp=c(1.5,0.5,0))
plot(rt_corr ~ edMom,data=data,xlab="",ylab="",pch=20,cex.lab=1,cex=3,cex.axis=1,type="n")
mtext("Ed mère (années)",1,line=2.5,cex=2)
mtext("RT corr (ms)",2,line=2.5,cex=2)
points(rt_corr ~ edMom,data=data,subset=c(lang=="monolingual"),pch=25,bg="red",col="red")
abline(lm(rt_corr ~  edMom,subset=c(lang=="monolingual" & !is.na(lang)),data=data),col="red")
points(rt_corr ~ edMom,data=data,subset=c(lang2=="other"),pch=20,col="black")
abline(lm(rt_corr ~  edMom,subset=c(lang2=="other" & !is.na(lang)),data=data),col="black")
#Plot PC and RT ~ edPar & lang
par(mar=c(4,4,1,1)+0.1,mgp=c(1.5,0.5,0))
plot(pc ~ edPar,data=data,xlab="",ylab="",pch=20,cex.lab=2,cex=3,cex.axis=1,type="n")
mtext("Ed Parents (années)",1,line=2.5,cex=2)
mtext("Réponses correctes (%)",2,line=2.5,cex=2)
points(pc ~ edPar,data=data,subset=c(lang=="monolingual" & !is.na(lang)),pch=25,bg="red",col="red")
abline(lm(pc ~ edPar,subset=c(lang=="monolingual" & !is.na(lang)),data=data),col="red")
points(pc ~ edPar,data=data,subset=c(lang2=="other" & !is.na(lang)),pch=20,col="black")
abline(lm(pc ~  edPar,subset=c(lang2=="other" & !is.na(lang)),data=data),col="black")
abline(h=0.5,lty=2,col="slategrey")
par(mar=c(4,4,1,1)+0.1,mgp=c(1.5,0.5,0))
plot(rt_corr ~ edPar,data=data,xlab="",ylab="",pch=20,cex.lab=1,cex=3,cex.axis=1,type="n")
mtext("Ed Parents (années)",1,line=2.5,cex=2)
mtext("RT corr (ms)",2,line=2.5,cex=2)
points(rt_corr ~ edPar,data=data,subset=c(lang=="monolingual"),pch=25,bg="red",col="red")
abline(lm(rt_corr ~  edPar,subset=c(lang=="monolingual" & !is.na(lang)),data=data),col="red")
points(rt_corr ~ edPar,data=data,subset=c(lang2=="other"),pch=20,col="black")
abline(lm(rt_corr ~  edPar,subset=c(lang2=="other" & !is.na(lang)),data=data),col="black")
#Plot PC and RT ~ age & lang
par(mar=c(4,4,1,1)+0.1,mgp=c(1.5,0.5,0))
plot(pc ~ age,data=data,xlab="",ylab="",pch=20,cex.lab=2,cex=2,cex.axis=1,type="n")
mtext("Age (ans)",1,line=2.5,cex=2)
mtext("Réponses correctes (%)",2,line=2.5,cex=2)
points(pc ~ age,data=data,subset=c(lang=="monolingual"),pch=25,col="red",bg="red")
abline(lm(pc ~  age,subset=c(lang=="monolingual" & !is.na(lang)),data=data),col="red",bg="red")
points(pc ~ age,data=data,subset=c(lang2=="other"),pch=16,col="black")
abline(lm(pc ~  age,subset=c(lang2=="other" & !is.na(lang)),data=data),col="black")
abline(h=0.5,lty=2,col="slategrey")
par(mar=c(4,4,1,1)+0.1,mgp=c(1.5,0.5,0))
plot(rt_corr ~ age,data=data,xlab="",ylab="",pch=20,cex.lab=2,cex=2,cex.axis=1,type="n")
mtext("Age (ans)",1,line=2.5,cex=2)
mtext("RT corr (ms)",2,line=2.5,cex=2)
points(rt_corr ~ age,data=data,subset=c(lang=="monolingual"),pch=25,col="red",bg="red")
abline(lm(rt_corr ~  age,subset=c(lang=="monolingual" & !is.na(lang)),data=data),col="red",bg="red")
points(rt_corr ~ age,data=data,subset=c(lang2=="other"),pch=16,col="black")
abline(lm(rt_corr ~  age,subset=c(lang2=="other" & !is.na(lang)),data=data),col="black")
##courbe PC and RT ~ sex
plot(pc ~ sex, data=data, xlab="", ylab="",pch=20,cex.lab=2,cex=2,cex.axis=1,type="n")
mtext("Sexe",1,line=2.5,cex=2)
mtext("Réponses correctes (%)",2,line=2.5,cex=2)
abline(h=0.5,lty=2,col="slategrey")
plot(rt_corr ~ sex, data=data, xlab="", ylab="",pch=20,cex.lab=2,cex=2,cex.axis=1,type="n")
mtext("Sexe",1,line=2.5,cex=2)
mtext("RT corr (ms)",2,line=2.5,cex=2)
##courbe RT ~ time    #rerun "_cm_1_new_preprocess.R" if needed
plot(data$object_touched_at ~ data$trial_number_session,xlab="",ylab="",ylim=c(1500,3000),pch=20,cex.lab=2,cex=2,cex.axis=1,type="n")
mtext("Essais",1,line=2.5,cex=2)
mtext("RT (ms)",2,line=2.5,cex=2)
abline(lm(data$object_touched_at ~ data$trial_number_session))
54/12
54/12
=
54/12*1
54/12
54*2
54*2/3
